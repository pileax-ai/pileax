# ############################################################
# Server Configuration
# ############################################################
# Environment Configuration
NODE_ENV="development"  # Options: 'development', 'production'
PORT="21000"            # The port your server will listen on
HOST="localhost"        # Hostname for the server
APP_MODE="SINGLE"       # SINGLE, MULTIPLE

# API
API_JWT_SECRET="60000"
API_JWT_DEFAULT_TOKEN="eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VySWQiOiIwMDAwMDAwMC0wMDAwLTAwMDAtMDAwMC0wMDAwMDAwMDAwMDAiLCJuYW1lIjoiRGVmYXVsdCIsImlhdCI6MTc0NDEwNjMxMywiZXhwIjoxNzQ2Njk4MzEzfQ.-mU7VI62bOz10Dn47PDhWqPAB0a66LcIc8aO0fgvYeU"
API_SIG_KEY="60000"
API_SIG_SALT="60000"

# CORS Settings
CORS_ORIGIN="http://localhost:21800" # Allowed CORS origin, adjust as necessary

# Rate Limiting
COMMON_RATE_LIMIT_WINDOW_MS="1000" # Window size for rate limiting (ms)
COMMON_RATE_LIMIT_MAX_REQUESTS="10000" # Max number of requests per window per IP

# Database
DATABASE_URL="src/storage/metadata.db"
SERVER_ROOT="."

# File server
PUBLIC_ROOT="src/storage/files"

# ############################################################
# LLM Configuration
# ############################################################
# LLM_PROVIDER='deepseek'
DEEPSEEK_API_KEY='sk-xxxx'
DEEPSEEK_MODEL='deepseek-chat'

# LLM_PROVIDER='ollama'
OLLAMA_BASE_PATH='http://localhost:11434'
OLLAMA_API_KEY=''
OLLAMA_MODEL='llama2'

# LLM_PROVIDER='openai'
OPENAI_API_KEY='sk-xxxx'
OPENAI_MODEL='gpt-4o'
